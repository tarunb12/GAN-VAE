{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EbagqptDFnHs"
   },
   "source": [
    "# MNIST Handwritten Digit Generation using DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0klXyUBkFnH5"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    print('Running TF without GPU')\n",
    "else:\n",
    "    print(f'Found GPU at {device_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "a8FP-IpMFnH9"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import glob\n",
    "import imageio\n",
    "import math\n",
    "import os\n",
    "import seaborn as sn\n",
    "import time\n",
    "\n",
    "from abc import abstractstaticmethod\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "\n",
    "sn.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_sStovFFnIA"
   },
   "source": [
    "## DCGAN Architecture\n",
    "\n",
    "Source: https://arxiv.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JCdGOCcCFnIC"
   },
   "outputs": [],
   "source": [
    "NOISE_DIMENSION = 128\n",
    "TRAIN_SIZE = 60000\n",
    "TEST_SIZE = 10000\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 200\n",
    "\n",
    "EPSILON = 1e-7\n",
    "N_EXAMPLES = 25\n",
    "G_LEARNING_RATE = 2e-4\n",
    "D_LEARNING_RATE = 2e-4\n",
    "\n",
    "ARCH = 'dcgan'\n",
    "path_prefix = ''\n",
    "\n",
    "IN_COLAB = False\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    path_prefix = '/content/drive/My Drive/gan-vae/gan/'\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    \n",
    "METRICS_PATH = f'{path_prefix}metrics/{ARCH}/'\n",
    "OUTPUT_PATH = f'{path_prefix}output/{ARCH}/'\n",
    "\n",
    "if not IN_COLAB:\n",
    "    !mkdir -p $METRICS_PATH\n",
    "    !mkdir -p $OUTPUT_PATH\n",
    "\n",
    "assert NOISE_DIMENSION > 0\n",
    "assert TRAIN_SIZE <= 600000\n",
    "assert TEST_SIZE <= 10000\n",
    "assert BATCH_SIZE >= 1\n",
    "assert EPOCHS >= 1\n",
    "assert EPSILON > 0\n",
    "assert N_EXAMPLES >= 1\n",
    "assert G_LEARNING_RATE > 0\n",
    "assert D_LEARNING_RATE > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MGTmf0kKFnIC"
   },
   "source": [
    "## Base Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "vgncfRdTFnID"
   },
   "outputs": [],
   "source": [
    "class BaseNetwork(tf.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    @tf.Module.with_name_scope\n",
    "    def __call__(self, input_data, training=False) -> tf.Tensor:\n",
    "        output_data = input_data\n",
    "        for layer in self.layers:\n",
    "            output_data = layer(output_data, training=training)\n",
    "        return output_data\n",
    "\n",
    "    @abstractstaticmethod\n",
    "    def loss() -> tf.Tensor:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractstaticmethod\n",
    "    def optimizer(*args, **kwargs) -> tf.optimizers.Optimizer:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mj1AlMzFnIE"
   },
   "source": [
    "## Generator Network\n",
    "### Layers\n",
    "<pre>\n",
    "Input:         input_size=(128, 1)\n",
    "Deconvolution:\n",
    "</pre>\n",
    "\n",
    "### Optimizer\n",
    "<pre>\n",
    "Adam:          learning_rate=0.0002\n",
    "</pre>\n",
    "\n",
    "### Loss\n",
    "&#8466;<sub>G</sub>(<i><b>z</b></i>) = <sup>-1</sup>&frasl;<sub>m</sub> &lowast; &sum;<sub><i>i</i></sub> log(<i>D</i>(G(<i><b>z</b><sup>(i)</sup></i>)))\n",
    "\n",
    "### Goal\n",
    "Find argmin<sub>G</sub> {&#8466;<sub>G</sub>(<i><b>z</b></i>)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "EMKdFvqRFnIF"
   },
   "outputs": [],
   "source": [
    "class Generator(BaseNetwork):\n",
    "    def __init__(self, noise_dimension: int, output_shape: tuple) -> None:\n",
    "        super().__init__()\n",
    "        # Network layers\n",
    "        self.layers = [\n",
    "            keras.layers.InputLayer(input_shape=(noise_dimension,)),\n",
    "            keras.layers.Dense(units=7*7*256),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Reshape(target_shape=(7, 7, 256)),\n",
    "            keras.layers.LeakyReLU(),\n",
    "            keras.layers.Conv2DTranspose(filters=128, kernel_size=(3, 3), strides=(1, 1), padding='same', use_bias=False),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.LeakyReLU(),\n",
    "            keras.layers.Conv2DTranspose(filters=64, kernel_size=(3, 3), strides=(2, 2), padding='same', use_bias=False),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.LeakyReLU(),\n",
    "            keras.layers.Conv2DTranspose(filters=1, kernel_size=(3, 3), strides=(2, 2), padding='same', use_bias=False),\n",
    "            keras.layers.Activation(tf.nn.tanh),\n",
    "        ]\n",
    "\n",
    "    @staticmethod\n",
    "    def optimizer(learning_rate: float, momentum: float=0.0) -> tf.optimizers.Optimizer:\n",
    "        return tf.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    @staticmethod\n",
    "    @tf.function\n",
    "    def loss(generated_output):\n",
    "        loss_i = tf.math.log(generated_output+EPSILON)\n",
    "        loss = -tf.math.reduce_mean(loss_i)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PyqiiYA3FnIF"
   },
   "source": [
    "## Discriminator Network\n",
    "### Layers\n",
    "<pre>\n",
    "<b>Input</b>:        input_size=(28, 28, 1)\n",
    "<b>Convolution</b>:  filters=32, kernel_size=(3, 3), strides=(1, 1), activation=ReLU\n",
    "<b>Max Pooling</b>:  pool_size=(2, 2)\n",
    "<b>Convolution</b>:  filters=64, kernel_size=(3, 3), strides=(1, 1), activation=ReLU\n",
    "<b>Max Pooling</b>:  pool_size=(2, 2)\n",
    "<b>Dense</b>:        units=512, activation=ReLU\n",
    "<b>Dropout</b>:      rate=0.3\n",
    "<b>Dense</b>:        units=256, activation=ReLU\n",
    "<b>Dropout</b>:      rate=0.2\n",
    "<b>Dense</b>:        units=1, activation=tanh\n",
    "</pre>\n",
    "\n",
    "### Optimizer\n",
    "<pre>\n",
    "<b>Adam</b>:         learning_rate=0.0002\n",
    "</pre>\n",
    "\n",
    "### Loss\n",
    "&#8466;<sub>D</sub>(<i><b>x</b>,<b>z</b>) = <sup>-1</sup>&frasl;<sub>m</sub> &lowast; &sum;<i><sub>i</sub></i> \\[log <i>D</i>(<i><b>x</b><sup>(i)</sup></i>) + log (1-<i>D</i>(G(<i><b>z</b><sup>(i)</sup></i>)))\\]\n",
    "\n",
    "### Goal\n",
    "Find argmin<sub>D</sub> &#8466;<sub>D</sub>(<i><b>x</b></i>,<i><b>z</b></i>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_vnGXX9CFnIH"
   },
   "outputs": [],
   "source": [
    "class Discriminator(BaseNetwork):\n",
    "    def __init__(self, input_shape: tuple) -> None:\n",
    "        super().__init__()\n",
    "        # Network layers\n",
    "        self.layers = [\n",
    "            keras.layers.InputLayer(input_shape=input_shape),\n",
    "            keras.layers.Conv2D(filters=64, kernel_size=(3, 3), strides=(2, 2)),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.LeakyReLU(),\n",
    "            keras.layers.Dropout(rate=0.3),\n",
    "            keras.layers.Conv2D(filters=128, kernel_size=(3, 3), strides=(2, 2)),\n",
    "            keras.layers.LeakyReLU(),\n",
    "            keras.layers.Dropout(rate=0.2),\n",
    "            keras.layers.Flatten(),\n",
    "            keras.layers.Dense(units=64),\n",
    "            keras.layers.Dropout(rate=0.1),\n",
    "            keras.layers.Dense(units=1),\n",
    "            keras.layers.Activation(tf.nn.sigmoid)\n",
    "        ]\n",
    "\n",
    "    @staticmethod\n",
    "    def optimizer(learning_rate: float, momentum: float=0.0):\n",
    "        return tf.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    @staticmethod\n",
    "    @tf.function\n",
    "    def loss(trained_ouput, generated_output) -> tf.Tensor:\n",
    "        loss_i = tf.math.log(trained_ouput+EPSILON) + tf.math.log1p(EPSILON-generated_output)\n",
    "        loss = -tf.math.reduce_mean(loss_i)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4k98Pv3FnIK"
   },
   "source": [
    "## Preprocessing\n",
    "* Import MNIST training images\n",
    "* Normalize to \\[-1, 1\\]\n",
    "* Shuffle and batch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "kW6LAdhWFnIM"
   },
   "outputs": [],
   "source": [
    "(train_images, _), (test_images, _) = keras.datasets.mnist.load_data()\n",
    "\n",
    "train_images = tf.dtypes.cast((train_images[:TRAIN_SIZE]-127.5) / 127.5, tf.float32)\n",
    "train_images = tf.expand_dims(input=train_images, axis=-1)\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(train_images) \\\n",
    "                          .shuffle(TRAIN_SIZE) \\\n",
    "                          .batch(BATCH_SIZE)\n",
    "\n",
    "test_images = tf.dtypes.cast((train_images[:TEST_SIZE]-127.5) / 127.5, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "asF-uHebFnIM"
   },
   "source": [
    "### Initialize Generator and Discriminator\n",
    "* Generator takes in 128-dimensional Gaussian sample, and outputs an image.\n",
    "* Discriminator takes in images, and outputs whether it is classified as data from the training distribution or generator distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "p9CAimXhFnIM"
   },
   "outputs": [],
   "source": [
    "generator = Generator(noise_dimension=NOISE_DIMENSION, output_shape=(train_images.shape[1:]))\n",
    "generator_optimizer = generator.optimizer(G_LEARNING_RATE)\n",
    "\n",
    "discriminator = Discriminator(input_shape=(train_images.shape[1:]))\n",
    "discriminator_optimizer = discriminator.optimizer(D_LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "wE5etOFoFnIN"
   },
   "outputs": [],
   "source": [
    "fixed_noise = tf.random.normal([N_EXAMPLES, NOISE_DIMENSION])\n",
    "metrics_names = ['g_loss', 'd_loss', 'acc', 'real_acc', 'fake_acc']\n",
    "batch_history = { name: [] for name in metrics_names }\n",
    "epoch_history = { name: [] for name in metrics_names }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "pgiURO16FnIO"
   },
   "outputs": [],
   "source": [
    "def record_sample(generator: Generator, epoch: int, save: bool=True, show=True):\n",
    "    fixed_predictions = generator(fixed_noise)[:, :, :, 0]\n",
    "    random_predictions = generator(tf.random.normal(fixed_noise.shape))[:, :, :, 0]\n",
    "\n",
    "    titles = ['Fixed Noise Samples', 'Variational Noise Samples']\n",
    "    data = [fixed_predictions, random_predictions]\n",
    "\n",
    "    f = plt.figure(figsize=(8, 4))\n",
    "    f.suptitle('GAN Output')\n",
    "    outer = gridspec.GridSpec(1, 2)\n",
    "\n",
    "    for i in range(2):\n",
    "        inner = gridspec.GridSpecFromSubplotSpec(int(math.sqrt(N_EXAMPLES)), int(math.sqrt(N_EXAMPLES)), subplot_spec=outer[i])\n",
    "        predictions = data[i]\n",
    "        for j in range(predictions.shape[0]):\n",
    "            ax = plt.Subplot(f, inner[j])\n",
    "            ax.imshow(predictions[j]*127.5 + 127.5, cmap=plt.cm.gray)\n",
    "            ax.axis('off')\n",
    "            if j == int(math.sqrt(N_EXAMPLES)) // 2:\n",
    "                ax.set_title(titles[i])\n",
    "            f.add_subplot(ax)\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(os.path.join(OUTPUT_PATH, 'epoch_{:04d}.png'.format(epoch)))\n",
    "    if show:\n",
    "        plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYqfjCh_FnIP"
   },
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fwWXq1OPFnIP"
   },
   "outputs": [],
   "source": [
    "def accuracy(trained_output, generated_output) -> tuple:\n",
    "    # Trained images fed into D have output 1, images from G's noisy\n",
    "    # distribution should have output 0 from D\n",
    "    correct_trained_output = tf.ones_like(trained_output)\n",
    "    correct_generated_ouput = tf.zeros_like(generated_output)\n",
    "\n",
    "    real_acc = tf.math.reduce_mean(tf.dtypes.cast(tf.math.equal(tf.math.round(trained_output), correct_trained_output), tf.float32))\n",
    "    fake_acc = tf.math.reduce_mean(tf.dtypes.cast(tf.math.equal(tf.math.round(generated_output), correct_generated_ouput), tf.float32))\n",
    "\n",
    "    return real_acc, fake_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fq5NQ3EaFnIQ"
   },
   "source": [
    "## GAN Algorithm\n",
    "<pre>\n",
    "<b>for</b> number of training iterations <b>do</b>\n",
    "  <b>for</b> k steps <b>do</b>\n",
    "     • Sample minibatch of <i>m</i> noise samples {<i><b>z</b><sup>(1)</sup>, ..., <b>z</b><sup>(m)</sup></i>} from noise prior <i>p<sub>g</sub>(<b>z</b>)</i>.\n",
    "     • Sample minibatch of <i>m</i> examples {<i><b>x</b><sup>(1)</sup>, ..., <b>x</b><sup>(m)</sup></i>} from data generating distribution <i>p<sub>data</sub>(<b>x</b>)</i>.\n",
    "     • Update the discriminator by <u>ascending</u> its stochastic gradient:\n",
    "       <center>&Del;<sub>&theta;<sub>d</sub></sub> <sup>1</sup>&frasl;<sub>m</sub> &lowast; &sum;<sub><i>i</i></sub> [log <i>D</i>(<i><b>x</b><sup>(i)</sup></i>) + log(1-<i>D</i>(G(<i><b>z</b><sup>(i)</sup></i>)))]</center>\n",
    "  <b>end for</b>\n",
    "  • Sample minibatch of <i>m</i> noise samples {<i><b>z</b><sup>(1)</sup>, ..., <b>z</b><sup>(m)</sup></i>} from noise prior <i>p<sub>g</sub>(<b>z</b>)</i>.\n",
    "  • Update the generator by <u>descending</u> its stochastic gradient:\n",
    "  <center>&Del;<sub>&theta;<sub>d</sub></sub> <sup>1</sup>&frasl;<sub>m</sub> &lowast; &sum;<sub><i>i</i></sub> log(1-<i>D</i>(G(<i><b>z</b><sup>(i)</sup></i>)))</center>\n",
    "<b>end for</b>\n",
    "</pre>\n",
    "\n",
    "Source: https://arxiv.org/pdf/1406.2661.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CZe1j-Q2FnIR"
   },
   "outputs": [],
   "source": [
    "# view_sample(generator, 1, fixed_noise)\n",
    "steps_per_epoch = train_images.shape[0] // BATCH_SIZE\n",
    "record_sample(generator, 0, show=False)\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    print(f'\\nepoch {epoch}/{EPOCHS}')\n",
    "    progress_bar = keras.utils.Progbar(steps_per_epoch, stateful_metrics=metrics_names)\n",
    "\n",
    "    for i, image_batch in enumerate(train_ds):\n",
    "\n",
    "        num_samples = image_batch.shape[0]\n",
    "        noise = tf.random.normal([num_samples, NOISE_DIMENSION])\n",
    "\n",
    "        with tf.GradientTape() as g_tape, tf.GradientTape() as d_tape:\n",
    "            # Train G on noise\n",
    "            generated_images = generator(noise, training=True)\n",
    "            # Train D on training images\n",
    "            trained_output = discriminator(image_batch, training=True)\n",
    "            # Train D on generated images\n",
    "            generated_output = discriminator(generated_images, training=True)\n",
    "\n",
    "            # Calculate loss\n",
    "            g_loss = generator.loss(generated_output)\n",
    "            d_loss = discriminator.loss(trained_output, generated_output)\n",
    "\n",
    "        real_acc, fake_acc = accuracy(trained_output, generated_output)\n",
    "        acc = 0.5 * (real_acc + fake_acc)\n",
    "\n",
    "        updated_metrics = {\n",
    "            'g_loss': g_loss,\n",
    "            'd_loss': d_loss,\n",
    "            'acc': acc,\n",
    "            'real_acc': real_acc,\n",
    "            'fake_acc': fake_acc,\n",
    "        }\n",
    "\n",
    "        # Record loss history\n",
    "        for metric in batch_history:\n",
    "            batch_history[metric].append(updated_metrics[metric])\n",
    "    \n",
    "        metric_values = updated_metrics.items()\n",
    "        progress_bar.update(min(i, steps_per_epoch), values=metric_values)        \n",
    "\n",
    "        # https://www.tensorflow.org/api_docs/python/tf/GradientTape#gradient\n",
    "        grad_g = g_tape.gradient(g_loss, generator.trainable_variables)\n",
    "        grad_d = d_tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "\n",
    "        # https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Optimizer#apply_gradients\n",
    "        generator_optimizer.apply_gradients(zip(grad_g, generator.trainable_variables))\n",
    "        discriminator_optimizer.apply_gradients(zip(grad_d, discriminator.trainable_variables))    \n",
    "\n",
    "    record_sample(generator, epoch, show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YLz_L-glFnIT"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(tf.math.reduce_mean(tf.reshape(batch_history['g_loss'], shape=(-1, math.ceil(TRAIN_SIZE / BATCH_SIZE))), axis=1), label='Generator Loss')\n",
    "plt.plot(tf.math.reduce_mean(tf.reshape(batch_history['d_loss'], shape=(-1, math.ceil(TRAIN_SIZE / BATCH_SIZE))), axis=1), label='Discriminator Loss')\n",
    "plt.xlabel('Epoch #')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('DCGAN Loss')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(METRICS_PATH, 'loss.png'))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XuH4WJETFnIV"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(tf.math.reduce_mean(tf.reshape(batch_history['acc'], shape=(-1, math.ceil(TRAIN_SIZE / BATCH_SIZE))), axis=1), label='Total Accuracy')\n",
    "plt.plot(tf.math.reduce_mean(tf.reshape(batch_history['real_acc'], shape=(-1, math.ceil(TRAIN_SIZE / BATCH_SIZE))), axis=1), label='Training Data Accuracy')\n",
    "plt.plot(tf.math.reduce_mean(tf.reshape(batch_history['fake_acc'], shape=(-1, math.ceil(TRAIN_SIZE / BATCH_SIZE))), axis=1), label='Generated Data Accuracy')\n",
    "plt.xlabel('Epoch #')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('DCGAN Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(METRICS_PATH, 'accuracy.png'))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with imageio.get_writer(os.path.join(METRICS_PATH, f'{ARCH}.gif'), mode='I') as writer:\n",
    "    filenames = glob.glob(os.path.join(OUTPUT_PATH, 'epoch*.png'))\n",
    "    filenames = sorted(filenames)\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "\n",
    "last_epoch_img = 'epoch_{:04d}'.format(EPOCHS)\n",
    "last_epoch_img_output = os.path.join(OUTPUT_PATH, last_epoch_img)\n",
    "last_epoch_img_metrics = os.path.join(METRICS_PATH, last_epoch_img)\n",
    "Image.open(last_epoch_img_output).save(last_epoch_img_metrics)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "dcgan_mnist.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "gan-vae",
   "language": "python",
   "name": "gan-vae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
